{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing all necessary dependencies"
      ],
      "metadata": {
        "id": "LkfpvgQoq2uk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfmoU9NNqufp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install openai tiktoken langchain\n",
        "!python -m spacy download es_core_news_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the dependencies"
      ],
      "metadata": {
        "id": "ArBz59q7rFfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import spacy"
      ],
      "metadata": {
        "id": "Lem6pMMGrGI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER for preprocessing the news to recover the location"
      ],
      "metadata": {
        "id": "aYoLi9TSrV1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_lg\")"
      ],
      "metadata": {
        "id": "pRpRDOhjrWK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_first_loc(text):\n",
        "    doc = nlp(text)\n",
        "    first_loc = next((ent.text for ent in doc.ents if ent.label_ == \"LOC\"), None) # Find the first entity of type LOC\n",
        "\n",
        "    return first_loc"
      ],
      "metadata": {
        "id": "s2uzJdOYrZGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing the news and generation function\n"
      ],
      "metadata": {
        "id": "KXiv1uffrejT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para GPT 3.5\n",
        "def generar_nueva_noticia_gpt_noticias(noticia, fecha):\n",
        "    client = openai\n",
        "\n",
        "    loc = extract_first_loc(noticia)\n",
        "\n",
        "    if(loc):\n",
        "            prompt = \"Crea un artículo de noticias con esta información: \" + noticia + \". \" + \"Fecha: \" + fecha + \".\" + \"Lugar: \" + loc + \".\"\n",
        "    else:\n",
        "            prompt = \"Crea un artículo de noticias con esta información: \" + noticia + \". \" + \"Fecha: \" + fecha\n",
        "\n",
        "    # Make the call to the OpenAI API to generate the new news\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\" \", # Put here your FT model name\n",
        "            temperature=1,\n",
        "            max_tokens=500,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Tu tarea es escribir artículos de noticia que contengan siempre una fecha, un lugar y un acontecimiento. No puedes inventar información que no se te da, utiliza lenguaje formal.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
        "            ]\n",
        "            )\n",
        "\n",
        "        nueva_noticia = completion.choices[0].message.content\n",
        "        return nueva_noticia\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar nueva noticia con OpenAI: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "CO5CFCc_rfDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "VfoIMp-drvsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \" \" # Put your OpenAI API key here!"
      ],
      "metadata": {
        "id": "xLwha-iPrxzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "AG0Mrrlwyely"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the news"
      ],
      "metadata": {
        "id": "SKvykvOmselV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Give information about the news. This is an example!\n",
        "noticia = \"Melbourne. El español Carlos Sainz (Ferrari), ganador del Gran Premio de Australia de Fórmula Uno, aseguró que confiaba en tener la capacidad de superar al tricampeón mundial y actual líder de la competencia, el neerlandés Max Verstappen (Red Bull), hoy en la tercera prueba de la temporada, e indicó que su triunfo demuestra que nunca hay que darse por vencido.\"\n",
        "fecha = \"25 de marzo del 2024\""
      ],
      "metadata": {
        "id": "HP6t7Wf9sgQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generar_nueva_noticia_gpt_noticias(noticia, fecha))"
      ],
      "metadata": {
        "id": "YVGUp_2vsiII"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}