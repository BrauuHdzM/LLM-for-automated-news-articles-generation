{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing all necessary dependencies"
      ],
      "metadata": {
        "id": "LkfpvgQoq2uk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfmoU9NNqufp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!python -m spacy download es_core_news_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the dependencies"
      ],
      "metadata": {
        "id": "ArBz59q7rFfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import spacy"
      ],
      "metadata": {
        "id": "Lem6pMMGrGI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER for preprocessing the news to recover the location"
      ],
      "metadata": {
        "id": "aYoLi9TSrV1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_lg\")"
      ],
      "metadata": {
        "id": "pRpRDOhjrWK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_first_loc(text):\n",
        "    doc = nlp(text)\n",
        "    first_loc = next((ent.text for ent in doc.ents if ent.label_ == \"LOC\"), None) # Find the first entity of type LOC\n",
        "\n",
        "    return first_loc"
      ],
      "metadata": {
        "id": "s2uzJdOYrZGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing the news and generation function\n"
      ],
      "metadata": {
        "id": "KXiv1uffrejT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama3(noticia, fecha):\n",
        "\n",
        "  loc = extract_first_loc(noticia)\n",
        "  if(loc):\n",
        "          input = \"Crea un artículo de noticias con esta información: \" + noticia + \". \" + \"Fecha: \" + fecha + \".\" + \"Lugar: \" + loc + \".\"\n",
        "  else:\n",
        "          input = \"Crea un artículo de noticias con esta información: \" + noticia + \". \" + \"Fecha: \" + fecha\n",
        "\n",
        "  alpaca_prompt = \"\"\"Tu tarea es escribir artículos de noticia que contengan siempre una fecha, un lugar y un acontecimiento. No puedes inventar información que no se te da, utiliza lenguaje formal.\n",
        "\n",
        "  ### Instruction:\n",
        "  {}\n",
        "\n",
        "  ### Input:\n",
        "  {}\n",
        "\n",
        "  ### Response:\n",
        "  {}\"\"\"\n",
        "\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "      alpaca_prompt.format(\n",
        "          \"Crea un artículo de noticias con esta información:\", # instruction\n",
        "          input, # input\n",
        "          \"\",\n",
        "      )\n",
        "  ], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "  outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "\n",
        "  text = tokenizer.batch_decode(outputs)\n",
        "\n",
        "  # Convertir lista a cadena (si hay más de un elemento)\n",
        "  text = \" \".join(text)\n",
        "\n",
        "  # Utilizar una expresión regular para encontrar el texto después de '### Response:'\n",
        "  response_text = re.search(r'### Response:\\s*(.*)', text, re.DOTALL)\n",
        "\n",
        "  # Si se encuentra la coincidencia, imprimir el texto\n",
        "  if response_text:\n",
        "      return  response_text.group(1).strip()\n",
        "  else:\n",
        "      return \"No se encontró '### Response:' en el texto.\""
      ],
      "metadata": {
        "id": "CO5CFCc_rfDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "VfoIMp-drvsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
      ],
      "metadata": {
        "id": "xLwha-iPrxzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"BrauuHdzM/llama3_noticias_espanol\",\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "\n",
        "FastLanguageModel.for_inference(model)"
      ],
      "metadata": {
        "id": "EuKzOxWur8oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the news"
      ],
      "metadata": {
        "id": "SKvykvOmselV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Give information about the news. This is an example!\n",
        "noticia = \"Melbourne. El español Carlos Sainz (Ferrari), ganador del Gran Premio de Australia de Fórmula Uno, aseguró que confiaba en tener la capacidad de superar al tricampeón mundial y actual líder de la competencia, el neerlandés Max Verstappen (Red Bull), hoy en la tercera prueba de la temporada, e indicó que su triunfo demuestra que nunca hay que darse por vencido.\"\n",
        "fecha = \"25 de marzo del 2024\""
      ],
      "metadata": {
        "id": "HP6t7Wf9sgQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_llama3(noticia, fecha)"
      ],
      "metadata": {
        "id": "YVGUp_2vsiII"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}