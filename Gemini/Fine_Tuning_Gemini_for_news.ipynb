{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWxKvwd-MSIV"
      },
      "source": [
        "### Authenticate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjS8Zy1ojIgc"
      },
      "source": [
        "The Gemini API lets you tune models on your own data. Since it's your data and\n",
        "your tuned models this needs stricter access controls than API-Keys can provide.\n",
        "\n",
        "Before you can run this tutorial, you'll need to\n",
        "[setup OAuth for your project](https://ai.google.dev/gemini-api/docs/oauth).\n",
        "\n",
        "\n",
        "In Colab the easiest wat to get setup is to copy the contents of your `client_secret.json` file into Colab's \"Secrets manager\" (under the key icon in the left panel) with the secret name `CLIENT_SECRET`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6zTC-3mJ0-2"
      },
      "source": [
        "This gcloud command turns the `client_secret.json` file into credentials that can be used to authenticate with the service.\n",
        "\n",
        "> Important: If you're running this in Colab, **don't just click the link it prints**. That will fail. Follow the instructions and copy the `gcloud` command it prints to your local machine and run it there, then paste the output from your local machine back here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FUwyB_MJ0-2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if 'COLAB_RELEASE_TAG' in os.environ:\n",
        "  from google.colab import userdata\n",
        "  import pathlib\n",
        "  pathlib.Path('client_secret.json').write_text(userdata.get('CLIENT_SECRET'))\n",
        "\n",
        "  # Use `--no-browser` in colab\n",
        "  !gcloud auth application-default login --no-browser --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\n",
        "else:\n",
        "  !gcloud auth application-default login --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHimx8NGMWDj"
      },
      "source": [
        "### Install the client library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbcf72bcb56d"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdIYSl2kN0cq"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8enrppafJPCX"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-MYZECwlRCq"
      },
      "source": [
        "You can check you existing tuned models with the `genai.list_tuned_model` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyWzoYFxU4r6"
      },
      "outputs": [],
      "source": [
        "for i, m in zip(range(5), genai.list_tuned_models()):\n",
        "  print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the dataset of news"
      ],
      "metadata": {
        "id": "J-LE9fl2f9gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!python -m spacy download es_core_news_lg"
      ],
      "metadata": {
        "id": "afK3hWeGgFD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import spacy"
      ],
      "metadata": {
        "id": "UMTUUWdZgFt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_lg\")\n",
        "data = load_dataset(\"BrauuHdzM/Noticias-con-resumen\")"
      ],
      "metadata": {
        "id": "2g6MEf-hgRde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_first_loc(text):\n",
        "    doc = nlp(text)\n",
        "    first_loc = next((ent.text for ent in doc.ents if ent.label_ == \"LOC\"), None) # Find the first entity of type LOC\n",
        "\n",
        "    return first_loc"
      ],
      "metadata": {
        "id": "4DsxI0PugUZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_conversation(context, example):\n",
        "\n",
        "    formatted_conversation = {\n",
        "        \"messages\": []\n",
        "    }\n",
        "\n",
        "    if(extract_first_loc(example[\"Contenido\"])):\n",
        "          content = \"Crea un artículo de noticias con esta información: \" + example[\"resumen\"] + \". \" + \"Fecha: \" + example[\"Fecha\"] + \". Lugar: \" + extract_first_loc(example[\"Contenido\"])\n",
        "    else:\n",
        "          content = \"Crea un artículo de noticias con esta información: \" + example[\"resumen\"] + \". \" + \"Fecha: \" + example[\"Fecha\"]\n",
        "\n",
        "    formatted_conversation[\"messages\"].append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": context\n",
        "        })\n",
        "\n",
        "    formatted_conversation[\"messages\"].append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": content\n",
        "        })\n",
        "\n",
        "    if(extract_first_loc(example[\"Contenido\"])):\n",
        "          content = \"El \" + example[\"Fecha\"] +  \", en \" + extract_first_loc(example[\"Contenido\"]) + \". \" + example[\"Contenido\"]\n",
        "    else:\n",
        "          content = \"El \" + example[\"Fecha\"] +  \". \" + example[\"Contenido\"]\n",
        "\n",
        "    formatted_conversation[\"messages\"].append({\n",
        "            \"role\": \"model\",\n",
        "            \"content\": content\n",
        "        })\n",
        "\n",
        "    return formatted_conversation"
      ],
      "metadata": {
        "id": "JHq3FUhhgWtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = 'Tu tarea es escribir artículos de noticia que contengan siempre una fecha, un lugar y un acontecimiento. No puedes inventar información que no se te da, utiliza lenguaje formal.'\n",
        "\n",
        "dataset = []\n",
        "ejemplo = []"
      ],
      "metadata": {
        "id": "ZAHXo2vxgZgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for elemento in data_mini:\n",
        "  ejemplo_formateado = format_conversation(system_message, elemento)\n",
        "  dataset.append(ejemplo_formateado)"
      ],
      "metadata": {
        "id": "cTExwUv-gdCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def save_to_jsonl(dataset, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for ejemplo in dataset:\n",
        "            json_line = json.dumps(ejemplo, ensure_ascii=False)\n",
        "            file.write(json_line + '\\n')"
      ],
      "metadata": {
        "id": "ZP3fQsPlgiHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_jsonl(dataset, 'noticias-100-resumen.jsonl')"
      ],
      "metadata": {
        "id": "-AhvhqFNg9RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhkXRzciv3Dp"
      },
      "source": [
        "## Create tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO8VZYAinLWc"
      },
      "source": [
        "To create a tuned model, you need to pass your dataset to the model in the `genai.create_tuned_model` method. You can do this be directly defining the input and output values in the call or importing from a file into a dataframe to pass to the method.\n",
        "\n",
        "For this example, you will tune a model to generate the next number in the sequence. For example, if the input is `1`, the model should output `2`. If the input is `one hundred`, the output should be `one hundred one`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-EBSe9wTbLB"
      },
      "outputs": [],
      "source": [
        "base_model = [\n",
        "    m for m in genai.list_models()\n",
        "    if \"createTunedModel\" in m.supported_generation_methods][0]\n",
        "base_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baHjHh1oTTTC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "name = f'generate-num-{random.randint(0,10000)}'\n",
        "operation = genai.create_tuned_model(\n",
        "    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\n",
        "    source_model=base_model.name,\n",
        "    training_data=dataset,\n",
        "    id = name,\n",
        "    epoch_count = 100,\n",
        "    batch_size=4,\n",
        "    learning_rate=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-As7ayWDK1w8"
      },
      "source": [
        "Your tuned model is immediately added to the list of tuned models, but its status is set to \"creating\" while the model is tuned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su64KgY4Uztj"
      },
      "outputs": [],
      "source": [
        "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUodUwZkKPi-"
      },
      "outputs": [],
      "source": [
        "model.state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8X5vkQv-3_"
      },
      "source": [
        "### Check tuning progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWI-vAh4LJIz"
      },
      "source": [
        "Use `metadata` to check the state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g08vqtxYLMxT"
      },
      "outputs": [],
      "source": [
        "operation.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lQ6gSMgK-kz"
      },
      "source": [
        "Wait for the training to finish using `operation.result()`, or `operation.wait_bar()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOUowIv1HgSE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "for status in operation.wait_bar():\n",
        "  time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cg868HzqOx5"
      },
      "source": [
        "You can cancel your tuning job any time using the `cancel()` method. Uncomment the line below and run the code cell to cancel your job before it finishes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQuJ70_hqJi9"
      },
      "outputs": [],
      "source": [
        "# operation.cancel()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}