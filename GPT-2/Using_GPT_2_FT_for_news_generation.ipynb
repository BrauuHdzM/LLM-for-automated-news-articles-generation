{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing all necessary dependencies"
      ],
      "metadata": {
        "id": "w8u3MbrinHvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwxQYeZwk3SW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m spacy download es_core_news_lg\n",
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the dependencies"
      ],
      "metadata": {
        "id": "7VnJkqfIoKBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "PmKr_IxylZO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER for preprocessing the news to recover the location"
      ],
      "metadata": {
        "id": "2HcW1QiuoPDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_lg\")"
      ],
      "metadata": {
        "id": "iz9KlUhplZzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_first_loc(text):\n",
        "    doc = nlp(text)\n",
        "    first_loc = next((ent.text for ent in doc.ents if ent.label_ == \"LOC\"), None) # Find the first entity of type LOC\n",
        "\n",
        "    return first_loc"
      ],
      "metadata": {
        "id": "3mCz3ss6ldMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing the news and generation function"
      ],
      "metadata": {
        "id": "BlN2LYkQofWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_nueva_noticia_gpt2(noticia, fecha):\n",
        "    loc = extract_first_loc(noticia)\n",
        "\n",
        "    if(loc):\n",
        "            prompt = noticia + \". \" + \"Fecha: \" + fecha + \".\" + \"Lugar: \" + loc + \".\" \"->:\"\n",
        "    else:\n",
        "            prompt = noticia + \". \" + \"Fecha: \" + fecha + \"->:\"\n",
        "\n",
        "    # Defines a prompt for text generation based on the processed news\n",
        "    input_text = prompt\n",
        "\n",
        "    # Tokenizes the input text\n",
        "    batch = tokenizer(input_text, return_tensors='pt').to('cuda')\n",
        "\n",
        "    # Generates text with the model, adjusting the temperature and other parameters for creativity\n",
        "    with torch.cuda.amp.autocast():\n",
        "        output_tokens = model.generate(\n",
        "            **batch,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.9,  # Adjusts the temperature to increase creativity\n",
        "            top_k=50,         # Limits to the top 50 most likely tokens for each selection\n",
        "            top_p=0.95,       # Uses nucleus sampling with a p value of 0.95\n",
        "            repetition_penalty=1.2  # Applies a penalty to repeated words to reduce repetition\n",
        "        )\n",
        "\n",
        "    # Decodes and displays the result\n",
        "    generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
        "\n",
        "    # Use a regular expression to find the text after '### Response:'\n",
        "    response_text = re.search(r'->:\\s*(.*)', generated_text, re.DOTALL)\n",
        "\n",
        "    # If a match is found, print the text\n",
        "    if response_text:\n",
        "        return response_text.group(1).strip()"
      ],
      "metadata": {
        "id": "_0mYn_P6lppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "C9e0q_7Gor3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_id = \"BrauuHdzM/fine-tuned-noticias-gpt2-spanishstories-NER\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=True, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ],
      "metadata": {
        "id": "S1rwLSyNlffU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the news"
      ],
      "metadata": {
        "id": "6JQOorqKovpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Give information about the news. This is an example!\n",
        "noticia = \"Melbourne. El español Carlos Sainz (Ferrari), ganador del Gran Premio de Australia de Fórmula Uno, aseguró que confiaba en tener la capacidad de superar al tricampeón mundial y actual líder de la competencia, el neerlandés Max Verstappen (Red Bull), hoy en la tercera prueba de la temporada, e indicó que su triunfo demuestra que nunca hay que darse por vencido.\"\n",
        "fecha = \"25 de marzo del 2024\""
      ],
      "metadata": {
        "id": "51MJfPvKlwEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generar_nueva_noticia_gpt2(noticia, fecha)"
      ],
      "metadata": {
        "id": "BSP4SpDelz06"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}