{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE5GJ6s7y0Xo"
      },
      "source": [
        "### Installing all necessary dependencies and login to HuggingFace Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otj46qRbtpnd"
      },
      "outputs": [],
      "source": [
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n",
        "!python -m spacy download es_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpYr24pR8T_0"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "7650BSUPZh0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOtwYRI3zzXI"
      },
      "source": [
        "### Setup the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg3fiQOvmI3Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"dquisi/story_spanish_gpt2_v2\",\n",
        "    device_map='auto',\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dquisi/story_spanish_gpt2_v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fTSZntA1iUG"
      },
      "source": [
        "### Freezing the original weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-gy-LxM0yAi"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  if param.ndim == 1:\n",
        "    param.data = param.data.to(torch.float32)\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwOTr7B3NlM3"
      },
      "source": [
        "### Setting up the LoRa Adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W1j6lxaNnxC"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    # Prints the number of trainable parameters in the model.\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iwHGzKBN6wk"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16, #attention heads\n",
        "    lora_alpha=32, #alpha scaling\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the dataset of news"
      ],
      "metadata": {
        "id": "-y6MRpkSfYGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import spacy\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "b-En94RAfbKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"BrauuHdzM/noticias-en-espanol\")\n",
        "print(data)"
      ],
      "metadata": {
        "id": "ARcd2iUDOJC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_lg\")"
      ],
      "metadata": {
        "id": "zCH_HYlLkBDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_first_loc(text):\n",
        "    doc = nlp(text)\n",
        "    first_loc = next((ent.text for ent in doc.ents if ent.label_ == \"LOC\"), None) # Find the first entity of type LOC\n",
        "\n",
        "    return first_loc"
      ],
      "metadata": {
        "id": "JebsBfqvj8ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_ner(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    ner_entities = [] # List to store all entities of type LOC\n",
        "\n",
        "    for ent in doc.ents: # Iterate over all entities and add those of type LOC to the list\n",
        "      ner_entities.append(ent.text)\n",
        "\n",
        "    all_ner = ' '.join(ner_entities) # Concatenates all entities of type LOC into a text string\n",
        "\n",
        "    return all_ner"
      ],
      "metadata": {
        "id": "cVvN9uY0gUo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_columns(example):\n",
        "    doc = nlp(example[\"Contenido\"])\n",
        "    entities_text = \"\\n\".join([f\"{ent.text} ({ent.label_})\" for ent in doc.ents])\n",
        "    example[\"entities\"] = entities_text\n",
        "\n",
        "    example[\"text\"] = example[\"Título\"] + \". \" + extract_all_ner(example[\"Contenido\"]) + \". Fecha: \" + example[\"Fecha\"] + \". Lugar: \" +  \"->: \" + \"El \"+ example[\"Fecha\"] +  \". \" + example[\"Contenido\"]\n",
        "    return example\n",
        "\n",
        "data['train'] = data['train'].map(merge_columns, remove_columns= 'Vínculo' )\n",
        "data['test'] = data['test'].map(merge_columns, remove_columns= 'Vínculo' )"
      ],
      "metadata": {
        "id": "b6fQzRl2faSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(lambda samples: tokenizer(samples['text']), batched=True) # mapping all the dataset"
      ],
      "metadata": {
        "id": "v2huC6dMh5vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdjWif4CVXR6"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ_HCYruWIHU"
      },
      "outputs": [],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data['train'],\n",
        "    eval_dataset=data['test'],\n",
        "    args=transformers.TrainingArguments(\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=100,\n",
        "        max_steps=10000,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=False,\n",
        "        logging_steps=100,\n",
        "        output_dir='outputs'\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "OtnpIfPbSIrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duak7T_B3VpJ"
      },
      "source": [
        "### Push the model adapters and tokenizer to the repository in HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxB6UV5XAvvP"
      },
      "outputs": [],
      "source": [
        "model.push_to_hub(\" \", #Your repository in HuggingFace\n",
        "                  use_auth_token=True,\n",
        "                  commit_message=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\"\", #Your repository in HuggingFace\n",
        "                      use_auth_token=True,\n",
        "                      commit_message=\"con NER\")"
      ],
      "metadata": {
        "id": "oImjfnY6U_qy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}